/*
 * Copyright (c) 2025 EdgeImpulse Inc.
 *
 * Generated by Edge Impulse and licensed under the applicable Edge Impulse
 * Terms of Service. Community and Professional Terms of Service
 * (https://edgeimpulse.com/legal/terms-of-service) or Enterprise Terms of
 * Service (https://edgeimpulse.com/legal/enterprise-terms-of-service),
 * according to your product plan subscription (the “License”).
 *
 * This software, documentation and other associated files (collectively referred
 * to as the “Software”) is a single SDK variation generated by the Edge Impulse
 * platform and requires an active paid Edge Impulse subscription to use this
 * Software for any purpose.
 *
 * You may NOT use this Software unless you have an active Edge Impulse subscription
 * that meets the eligibility requirements for the applicable License, subject to
 * your full and continued compliance with the terms and conditions of the License,
 * including without limitation any usage restrictions under the applicable License.
 *
 * If you do not have an active Edge Impulse product plan subscription, or if use
 * of this Software exceeds the usage limitations of your Edge Impulse product plan
 * subscription, you are not permitted to use this Software and must immediately
 * delete and erase all copies of this Software within your control or possession.
 * Edge Impulse reserves all rights and remedies available to enforce its rights.
 *
 * Unless required by applicable law or agreed to in writing, the Software is
 * distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
 * either express or implied. See the License for the specific language governing
 * permissions, disclaimers and limitations under the License.
 */

#ifndef _EI_CLASSIFIER_MODEL_VARIABLES_H_
#define _EI_CLASSIFIER_MODEL_VARIABLES_H_

/**
 * @file
 *  Auto-generated complete impulse definitions. The ei_impulse_handle_t should
 *  be passed to ei_run_classifier() function to use this specific impulse.
 *  This file should only be included in ei_run_classifier.h file.
 */

#include <stdint.h>
#include "model_metadata.h"


#include "edge-impulse-sdk/classifier/ei_model_types.h"
#include "edge-impulse-sdk/classifier/inferencing_engines/engines.h"
#include "edge-impulse-sdk/classifier/postprocessing/ei_postprocessing_common.h"

const char* ei_classifier_inferencing_categories_52_1[] = { "chair", "computer", "cup_mug", "pen", "person" };

EI_CLASSIFIER_DSP_AXES_INDEX_TYPE ei_dsp_config_52_22_axes[] = { 0 };
const uint32_t ei_dsp_config_52_22_axes_size = 1;
ei_dsp_config_image_t ei_dsp_config_52_22 = {
    22, // uint32_t blockId
    1, // int implementationVersion
    1, // int length of axes
    NULL, // named axes
    0, // size of the named axes array
    "RGB" // select channels
};

const uint8_t ei_dsp_blocks_52_1_size = 1;
ei_model_dsp_t ei_dsp_blocks_52_1[ei_dsp_blocks_52_1_size] = {
    { // DSP block 22
        22,
        12288, // output size
        &extract_image_features, // DSP function pointer
        (void*)&ei_dsp_config_52_22, // pointer to config struct
        ei_dsp_config_52_22_axes, // array of offsets into the input stream, one for each axis
        ei_dsp_config_52_22_axes_size, // number of axes
        1, // version
        nullptr, // factory function
        nullptr, // data normalization config
    }
};
const ei_config_tensaiflow_graph_t ei_config_graph_52_23 = {
    .implementation_version = 1,
    .input_datatype = EI_CLASSIFIER_DATATYPE_INT8,
    .input_quantized = 1,
    .input_scale = 0.003921568859368563,
    .input_zeropoint = -128,
    .output_datatype = EI_CLASSIFIER_DATATYPE_INT8,
    .output_quantized = 1,
    .output_scale = 0.00390625,
    .output_zeropoint = -128,
    .output_features_count = 5
};

const uint8_t ei_output_tensors_indices_52_23[1] = { 0 };
const uint8_t ei_output_tensors_size_52_23 = 1;
ei_learning_block_config_tflite_graph_t ei_learning_block_config_52_23 = {
    .implementation_version = 1,
    .block_id = 23,
    .output_tensors_indices = ei_output_tensors_indices_52_23,
    .output_tensors_size = ei_output_tensors_size_52_23,
    .quantized = 1,
    .compiled = 0,
    .graph_config = (void*)&ei_config_graph_52_23,
    .dequantize_output = 0,
};

const uint8_t ei_learning_blocks_52_1_size = 1;
const uint32_t ei_learning_block_52_23_inputs[1] = { 22 };
const uint8_t ei_learning_block_52_23_inputs_size = 1;
const ei_learning_block_t ei_learning_blocks_52_1[ei_learning_blocks_52_1_size] = {
    {
        23,
        &run_nn_inference,
        (void*)&ei_learning_block_config_52_23,
        EI_CLASSIFIER_IMAGE_SCALING_NONE,
        ei_learning_block_52_23_inputs,
        ei_learning_block_52_23_inputs_size,
    },
};

ei_fill_result_classification_i8_config_t ei_fill_result_classification_i8_config_52_23 = {
    .zero_point = -128,
    .scale = 0.00390625
};

const size_t ei_postprocessing_blocks_52_1_size = 1;
const ei_postprocessing_block_t ei_postprocessing_blocks_52_1[ei_postprocessing_blocks_52_1_size] = {
    {
        .block_id = 23,
        .type = EI_CLASSIFIER_MODE_CLASSIFICATION,
        .init_fn = NULL,
        .deinit_fn = NULL,
        .postprocess_fn = &process_classification_i8,
        .display_fn = NULL,
        .config = (void*)&ei_fill_result_classification_i8_config_52_23,
        .input_block_id = 23
    },
};

const uint8_t freeform_outputs_52_1_size = 0;

uint32_t *freeform_outputs_52_1 = nullptr;


const ei_impulse_t impulse_52_1 = {
    .project_id = 52,
    .project_owner = "Edge Impulse Profiling",
    .project_name = "Demo: Image Recognition (Tensaiflow)",
    .impulse_id = 1,
    .impulse_name = "Impulse #1",
    .deploy_version = 5,

    .nn_input_frame_size = 12288,
    .raw_sample_count = 4096,
    .raw_samples_per_frame = 1,
    .dsp_input_frame_size = 4096 * 1,
    .input_width = 64,
    .input_height = 64,
    .input_frames = 1,
    .interval_ms = 1,
    .frequency = 0,

    .dsp_blocks_size = ei_dsp_blocks_52_1_size,
    .dsp_blocks = ei_dsp_blocks_52_1,

    .learning_blocks_size = ei_learning_blocks_52_1_size,
    .learning_blocks = ei_learning_blocks_52_1,

    .postprocessing_blocks_size = ei_postprocessing_blocks_52_1_size,
    .postprocessing_blocks = ei_postprocessing_blocks_52_1,

    .output_tensors_size = 1,

    .inferencing_engine = EI_CLASSIFIER_TENSAIFLOW,

    .sensor = EI_CLASSIFIER_SENSOR_CAMERA,
    .fusion_string = "image",
    .slice_size = (4096/4),
    .slices_per_model_window = 4,

    .has_anomaly = EI_ANOMALY_TYPE_UNKNOWN,
    .label_count = 5,
    .categories = ei_classifier_inferencing_categories_52_1,
    .freeform_outputs_size = freeform_outputs_52_1_size,
    .freeform_outputs = freeform_outputs_52_1
};

ei_impulse_handle_t impulse_handle_52_1 = ei_impulse_handle_t( &impulse_52_1 );
ei_impulse_handle_t& ei_default_impulse = impulse_handle_52_1;
constexpr auto& ei_classifier_inferencing_categories = ei_classifier_inferencing_categories_52_1;
const auto ei_dsp_blocks_size = ei_dsp_blocks_52_1_size;
ei_model_dsp_t *ei_dsp_blocks = ei_dsp_blocks_52_1;

#endif // _EI_CLASSIFIER_MODEL_VARIABLES_H_
